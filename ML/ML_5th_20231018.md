## 의사결정트리(Decision tree) 알고리즘
질문을 던지고, 질문에 대한 답변을 찾는 과정으로 그 범위를 좁혀가면서 진행. 분류 문제 해결 가능. 
- 문제 정의 -> 데이터 획득 -> 데이터를 나눌 때 가장 좋은 질문을 해서 데이터를 나누는 것이 중요함. 이때 사용되는 것이 엔트로피와 지니계수임. 질문을 던지기 전과 던진 후의 데이터 상태를 비교해서, 후보 해의 개수가 줄었는 지를 파악하는 것이 의사결정트리 알고리즘의 핵심이다.
- 어떤 항목에 대한 관측 값(입력값)과 목표 값(분류결과)을 연결해 주는 예측 모델로서 결정 트리를 사용하는 머신러닝 방법
- 초기에 주어진 데이터를 좋은 질문을 던져서 명확하게 잘 나눠지도록 해야 하는 것이 우리의 목표. 데이터가 섞여 있어서 복잡도 높은 것을 엔트로피가 가장 높을 때라고 함. 엔트로피는 데이터의 복잡도를 의미. 엔트로피를 낮추는 질문을 찾는 것이 목표. 엔트로피가 가장 높을 때가 1, 가장 낮을 때가 0. 질문을 던지기 전의 엔트로피가 1에서 질문을 던진 후의 엔트로피가 0임. 1 - 0을 Information gain(정보획득)이라고 부른다. 엔트로피 또는 지니계수를 통해 정보획득 양을 늘릴 수 있다.
- 독립변수가 여러개 있을 때, 그 중에서 영향력이 가장 큰 변수를 찾는 것이 중요함. 이런 변수를 상위 노드로, 영향력이 작은 변수를 하위 노드로 선택.
- 독립 변수 간의 영향력을 비교하는 방법: 엔트로피, 지니지수
- 엔트로피(Entropy): 불확실성을 수치로 나타낸 것
- 정보가 점점 더 획득(정보이득)될수록, 정보에 대한 불확실성(엔트로피)은 줄어들게 된다.
- 정보이득(Information gain) = 질문 전 엔트로피 - 질문 후 엔트로피
- 지니계수: 얼마나 많은 데이터들이 섞여있는지(불순도)를 나타내는 불확실성을 의미. 0~0.5의 값을 갖는다. 지니계수가 낮을수록 불확실성이 낮다. 0.5일때가 최대로 데이터가 반반씩 섞여있는 경우임. 엔트로피보다 속도가 빠름. 디폴트로 설정되어 있음.
- 의사결정트리는 다중분류에도 탁월한 성능을 보임
- 단점: 과대적합의 위험성이 높다. 최적의 솔루션을 보장하지 않는다
